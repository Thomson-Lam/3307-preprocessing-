{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db9a91e-79b7-49fc-80d9-2088165b38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhan/3307-preprocess/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/yasserh/titanic-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22.0k/22.0k [00:00<00:00, 13.9MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /home/zhan/.cache/kagglehub/datasets/yasserh/titanic-dataset/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yasserh/titanic-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a967c93-5639-4c71-903b-0e232b76ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib as plt\n",
    "import os \n",
    "import scikitlearn as sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0757a3-2292-45ba-8735-a6858a606c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data cleaning strategy:\n",
    "\n",
    "1. check data columns - what kind of data, and whether random split is fine? Any time/ other data leakages possible? \n",
    "2. drop the ID and name column \n",
    "3. train test split \n",
    "4. check for missing values and outliers, impute the whole dataset using values calculated from the train set  \n",
    "5. encode categorical variables \n",
    "6. scale features using values calculated from the train set\n",
    "7. save both train and test dataset splits as separate CSVs for the DIY machine learning library to test with  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6f45a-9a1b-400a-a578-dd929a23f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the csv \n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# check data columns \n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
